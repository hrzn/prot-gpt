{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GPT model on protein sequences\n",
    "\n",
    "Compared to Shakespeare, we implement a few changes:\n",
    "\n",
    "* We want to train the model to predict protein sequences in isolation from one another; i.e. independent of the sequences shown before.\n",
    "* We want to handle the case where proteins have variables sizes, and some are shorter than the block size. To handle variable-sized proteins in batches we'll use padding with a special token and mask it later on to block the attention mechanism from/to this special token.\n",
    "* We want to use PyTorch Lightning to make our life a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nano_transformer import NanoTransformer\n",
    "\n",
    "\n",
    "fname = \"data/prot_seqs.txt\"\n",
    "\n",
    "# hyperparameters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 32 if device == \"cpu\" else 64\n",
    "block_size = 8 if device == \"cpu\" else 256  # context size\n",
    "n_embd = 16 if device == \"cpu\" else 384  # called d_model in paper\n",
    "n_blocks = 2 if device == \"cpu\" else 6  # number N of transformer blocks\n",
    "# head_size = 32  # called d_k = d_v\n",
    "num_heads = 2 if device == \"cpu\" else 6  # nr attention heads\n",
    "dropout = 0.2\n",
    "max_iters = 5000\n",
    "eval_interval = 500 if device == \"cpu\" else 10\n",
    "learning_rate = 1e-3 if device == \"cpu\" else 3e-4\n",
    "\n",
    "eval_iters = 200\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fname, \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding amino acid tokens\n",
    "\n",
    "Note: There are 24 amino acids in this dataset.\n",
    "`{'U', 'X', 'O', 'Z'}` are present but not \"commonly\" known amino acids\n",
    "See: https://en.wikipedia.org/wiki/FASTA_format for meaning.\n",
    "\n",
    "In addition:\n",
    "* `\\n` means \"end of protein\"\n",
    "* `!` is our special padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad = \"!\"  # padding character\n",
    "flat_text = [c for line in lines for c in line]  # all proteins concatenated\n",
    "chars = sorted(set(flat_text)) + [pad]\n",
    "vocab_size = len(chars)\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "itos = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "\n",
    "\n",
    "counter = Counter(flat_text)\n",
    "plt.bar(counter.keys(), counter.values(), log=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):    \n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(i):\n",
    "    return \"\".join([itos[ii] for ii in i])\n",
    "\n",
    "def encode_batch(batch_lines):\n",
    "    # encode with padding to either block_size+1 or max_length+1\n",
    "    encodings = [encode(line) for line in batch_lines]\n",
    "    max_length = max([len(line) for line in encodings])\n",
    "    final_length = max(block_size+1, max_length+1)\n",
    "    for encoding in encodings:\n",
    "        if len(encoding) < final_length:\n",
    "            encoding += [stoi[pad]] * (final_length - len(encoding))\n",
    "    return encodings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "# There is one line per protein.\n",
    "# We shuffle for train/val split (done in place).\n",
    "random.shuffle(lines)\n",
    "\n",
    "n = int(0.9 * len(lines))\n",
    "train_lines = lines[:n]\n",
    "val_lines = lines[n:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "\n",
    "TODO: return lengths of each sequences in order to know how to mask later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, block_size, split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    lines_to_consider = train_lines if split == \"train\" else val_lines\n",
    "\n",
    "    # ids of proteins in batch\n",
    "    prot_idxs = [random.randint(0, len(lines_to_consider) - 1) for _ in range(batch_size)]\n",
    "    batch_lines = [lines_to_consider[i] for i in prot_idxs]\n",
    "\n",
    "    # encode with padding to max(block_size+1, max_length+1)\n",
    "    prots_encoded = encode_batch(batch_lines)\n",
    "\n",
    "    # get random start positions for each protein; make sure we don't fetch subsequences made of padding\n",
    "    start_idxs = [random.randint(0, max(0, len(batch_lines[i]) - block_size - 1))\n",
    "                  for i in range(batch_size)]\n",
    "    \n",
    "    # build torch tensors\n",
    "    x = torch.stack([torch.tensor(prots_encoded[i][start_idxs[i] : start_idxs[i] + block_size], dtype=torch.long)\n",
    "                     for i in range(batch_size)])\n",
    "    y = torch.stack([torch.tensor(prots_encoded[i][start_idxs[i] + 1 : start_idxs[i] + block_size + 1], dtype=torch.long) \n",
    "                     for i in range(batch_size)])\n",
    "    lengths_x = torch.tensor([len(batch_lines[i]) for i in range(batch_size)], dtype=torch.long)\n",
    "\n",
    "    x, y, lengths_x = x.to(device), y.to(device), lengths_x.to(device)\n",
    "    return x, y, lengths_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4, 14, 20, 18, 20, 17, 21, 12, 17,  6,  1, 10, 18, 17,  6, 20],\n",
      "        [ 6, 10, 20, 14, 16,  6, 17, 10, 10, 10, 16, 16, 15, 10,  1,  4],\n",
      "        [ 9,  8, 17,  2,  9,  1, 17,  6, 23, 18,  5, 18,  4, 23, 14, 11]])\n",
      "tensor([[14, 20, 18, 20, 17, 21, 12, 17,  6,  1, 10, 18, 17,  6, 20,  7],\n",
      "        [10, 20, 14, 16,  6, 17, 10, 10, 10, 16, 16, 15, 10,  1,  4, 10],\n",
      "        [ 8, 17,  2,  9,  1, 17,  6, 23, 18,  5, 18,  4, 23, 14, 11, 10]])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "random.seed(7)\n",
    "\n",
    "x, y, l = get_batch(3, 16, \"train\")\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(l.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some logic to obtain a (B, T, T) mask that prevents communication between padded tokens and the other tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# a toy example on a small batch of size B\n",
    "x_tmp = torch.tensor([[1,2,3,25,25],\n",
    "                      [1,2,25,25,25]])\n",
    "lengths = torch.tensor([3,2])\n",
    "maxlen = x_tmp.shape[1]\n",
    "\n",
    "mask = torch.arange(maxlen)[None, :] < lengths[:, None]\n",
    "print(mask)\n",
    "\n",
    "# mask = mask.to(torch.uint8)\n",
    "# print(mask)\n",
    "\n",
    "mask = mask[:, None, :]\n",
    "mask = mask & mask.transpose(-2, -1)\n",
    "\n",
    "weights = torch.randn(2, 5, 5)\n",
    "weights = weights.masked_fill(~mask, float(\"-inf\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007482 M parameters\n",
      "step 0: train loss 3.3878, val loss 3.3752\n",
      "step 500: train loss 2.8823, val loss 2.8909\n",
      "step 1000: train loss 2.8728, val loss 2.8695\n",
      "step 1500: train loss 2.8674, val loss 2.8674\n",
      "step 2000: train loss 2.8674, val loss 2.8636\n",
      "step 2500: train loss 2.8579, val loss 2.8666\n",
      "step 3000: train loss 2.8521, val loss 2.8561\n",
      "step 3500: train loss 2.8472, val loss 2.8519\n",
      "step 4000: train loss 2.8484, val loss 2.8488\n",
      "step 4500: train loss 2.8514, val loss 2.8540\n",
      "training duration: 28.93 s.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y, Ls = get_batch(batch_size, block_size, split)\n",
    "            _, loss = model(X, Y, Ls)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "model = NanoTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embd=n_embd,\n",
    "    n_blocks=n_blocks,\n",
    "    num_heads=num_heads,\n",
    "    dropout=dropout,\n",
    ")\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "tic = time.time()\n",
    "for iter in range(max_iters):\n",
    "    # evaluate loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(\n",
    "            f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
    "        )\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb, lb = get_batch(batch_size, block_size, \"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb, lb)\n",
    "    optimizer.zero_grad(set_to_none=None)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"training duration: {(time.time() - tic):.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_line(model, first_char_idx, termination_token_idx):\n",
    "    idx = torch.tensor([[first_char_idx]], dtype=torch.long, device=device)  # (1, 1)\n",
    "\n",
    "    while idx[0][-1].item() != termination_token_idx:\n",
    "        # length = torch.tensor([[idx.shape[1]]], dtype=torch.long, device=device)  # (1, 1)\n",
    "        logits, _ = model(idx=idx[:, -block_size :])\n",
    "                          # lengths=length)\n",
    "        # print(logits)\n",
    "        logits = logits[:, -1, :]  # (B, C)\n",
    "        probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        # print(idx)\n",
    "    return idx[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EKHYQAGGRGLQLQVPELVRSPRKANTFARLKAALMKPNVSAIHFMTQKIDGMPTGKSPPTTVNVHLPSSTAIEEKPGKEFPRGRLEKGMYLDHWVLKGMDQNV\n",
      "LEVNETLYMVINFILPWLPMQLTVGQTVVQDSRALQESDGGPNEKALEAYSQLKLIIMKYRVTYQIDGTFSDTKAIITGFTGAEATVKKLA\n",
      "EGLLVEEGLDRPGSESAEYDLWGISHLQFYNHSSNAQILDRKRLWPAEEHEGMLRDLVAAL\n"
     ]
    }
   ],
   "source": [
    "# set numpy and torch seed for reproducibility\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "def generate_protein_string():\n",
    "    # generate from the model\n",
    "    # TODO: actually use probability for an AA to be first in a protein\n",
    "    start_char_proba = {k: v / sum(counter.values()) for k, v in counter.items()}\n",
    "    start_char = np.random.choice(list(start_char_proba.keys()), p=list(start_char_proba.values()))\n",
    "    # context = torch.tensor([[stoi[start_char]]], dtype=torch.long, device=device)\n",
    "\n",
    "    return decode(generate_line(model, \n",
    "                            first_char_idx=stoi[start_char],\n",
    "                            termination_token_idx=stoi[\"\\n\"]).tolist()[:-1])  # remove the last \\n\n",
    "\n",
    "for _ in range(5):\n",
    "    print(generate_protein_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce1b89515fef3d4cfef6e9104e9edf9e02f437173acd0f1472bac3c815597244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
