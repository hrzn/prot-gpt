{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GPT model on protein sequences (development notebook)\n",
    "\n",
    "Compared to Shakespeare, we implement a few changes:\n",
    "\n",
    "* We want to train the model to predict protein sequences in isolation from one another; i.e. independent of the sequences shown before.\n",
    "* We want to handle the case where proteins have variables sizes, and some are shorter than the block size. To handle variable-sized proteins in batches we'll use padding with a special token and mask it later on to block the attention mechanism from/to this special token.\n",
    "* We want to use PyTorch Lightning to make our life a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Sampler\n",
    "from typing import Tuple\n",
    "\n",
    "from nano_transformer import NanoTransformer\n",
    "\n",
    "\n",
    "fname = \"data/prot_seqs.txt\"\n",
    "\n",
    "# hyperparameters\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32 if DEVICE == \"cpu\" else 64\n",
    "BLOCK_SIZE = 8 if DEVICE == \"cpu\" else 256  # context size\n",
    "N_EMBD = 16 if DEVICE == \"cpu\" else 384  # called d_model in paper\n",
    "N_BLOCKS = 2 if DEVICE == \"cpu\" else 6  # number N of transformer blocks\n",
    "NUM_HEADS = 2 if DEVICE == \"cpu\" else 6  # nr attention heads\n",
    "DROPOUT = 0.2\n",
    "MAX_ITERS = 5000\n",
    "EVAL_INTERVAL = 500 if DEVICE == \"cpu\" else 10\n",
    "LEARNING_RATE = 1e-3 if DEVICE == \"cpu\" else 3e-4\n",
    "EVAL_ITERS = 200\n",
    "print(f\"device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fname, \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding amino acid tokens\n",
    "\n",
    "Note: There are 24 amino acids in this dataset.\n",
    "`{'U', 'X', 'O', 'Z'}` are present but not \"commonly\" known amino acids\n",
    "See: https://en.wikipedia.org/wiki/FASTA_format for meaning.\n",
    "\n",
    "In addition:\n",
    "* `\\n` means \"end of protein\"\n",
    "* `!` is our special padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad = \"!\"  # padding character\n",
    "flat_text = [c for line in lines for c in line]  # all proteins concatenated\n",
    "chars = sorted(set(flat_text)) + [pad]\n",
    "vocab_size = len(chars)\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "itos = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "counter = Counter(flat_text)\n",
    "plt.bar(counter.keys(), counter.values(), log=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):    \n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(i):\n",
    "    return \"\".join([itos[ii] for ii in i])\n",
    "\n",
    "def encode_pad(s, block_size):\n",
    "    encoding = encode(s)\n",
    "    return encoding + [stoi[pad]] * max(0, block_size + 1 - len(encoding))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "# There is one line per protein.\n",
    "# We shuffle for train/val split (done in place).\n",
    "random.shuffle(lines)\n",
    "\n",
    "n = int(0.9 * len(lines))\n",
    "train_lines = lines[:n]\n",
    "val_lines = lines[n:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 - without PyTorch Lightning\n",
    "\n",
    "### Data loader\n",
    "\n",
    "Extract subsequences then pad to block size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(batch_lines, block_size):\n",
    "    # encode with padding to block_size+1\n",
    "    return [encode_pad(line, block_size) for line in batch_lines]\n",
    "\n",
    "def get_batch(batch_size, block_size, split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    lines_to_consider = train_lines if split == \"train\" else val_lines\n",
    "\n",
    "    # ids of proteins in batch\n",
    "    prot_idxs = [random.randint(0, len(lines_to_consider) - 1) for _ in range(batch_size)]\n",
    "    batch_lines = [lines_to_consider[i] for i in prot_idxs]\n",
    "\n",
    "    # encode with padding to block_size+1\n",
    "    prots_encoded = encode_batch(batch_lines, block_size)\n",
    "\n",
    "    # get random start positions for each protein; make sure we don't fetch subsequences made of padding\n",
    "    start_idxs = [random.randint(0, max(0, len(batch_lines[i]) - block_size - 1))\n",
    "                  for i in range(batch_size)]\n",
    "    \n",
    "    # build torch tensors\n",
    "    x = torch.stack([torch.tensor(prots_encoded[i][start_idxs[i] : start_idxs[i] + block_size], dtype=torch.long)\n",
    "                     for i in range(batch_size)])\n",
    "    y = torch.stack([torch.tensor(prots_encoded[i][start_idxs[i] + 1 : start_idxs[i] + block_size + 1], dtype=torch.long) \n",
    "                     for i in range(batch_size)])\n",
    "    lengths_x = torch.tensor([len(batch_lines[i]) for i in range(batch_size)], dtype=torch.long)\n",
    "\n",
    "    x, y, lengths_x = x.to(DEVICE), y.to(DEVICE), lengths_x.to(DEVICE)\n",
    "    return x, y, lengths_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "\n",
    "x, y, l = get_batch(3, 32, \"train\")\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some logic to obtain a (B, T, T) mask that prevents communication between padded tokens and the other tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a toy example on a small batch of size B\n",
    "x_tmp = torch.tensor([[1,2,3,25,25],\n",
    "                      [1,2,25,25,25]])\n",
    "lengths = torch.tensor([3,2])\n",
    "maxlen = x_tmp.shape[1]\n",
    "\n",
    "mask = torch.arange(maxlen)[None, :] < lengths[:, None]\n",
    "print(mask)\n",
    "\n",
    "# mask = mask.to(torch.uint8)\n",
    "# print(mask)\n",
    "\n",
    "mask = mask[:, None, :]\n",
    "mask = mask & mask.transpose(-2, -1)\n",
    "\n",
    "weights = torch.randn(2, 5, 5)\n",
    "weights = weights.masked_fill(~mask, float(\"-inf\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(EVAL_ITERS)\n",
    "        for k in range(EVAL_ITERS):\n",
    "            X, Y, Ls = get_batch(BATCH_SIZE, BLOCK_SIZE, split)\n",
    "            _, loss = model(X, Y, Ls)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "model = NanoTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embd=N_EMBD,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "tic = time.time()\n",
    "for iter in range(MAX_ITERS):\n",
    "    # evaluate loss on train and val sets\n",
    "    if iter % EVAL_INTERVAL == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(\n",
    "            f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
    "        )\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb, lb = get_batch(BATCH_SIZE, BLOCK_SIZE, \"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb, lb)\n",
    "    optimizer.zero_grad(set_to_none=None)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"training duration: {(time.time() - tic):.2f} s.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate, we'll use the base rates of each AA appearing in first position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_times_first = Counter([line[0] for line in train_lines])\n",
    "aa_to_proba_first = {aa: nr_times_first[aa] / len(train_lines) for aa in nr_times_first}\n",
    "\n",
    "plt.bar(aa_to_proba_first.keys(), aa_to_proba_first.values())\n",
    "plt.xlabel(\"amino acid\")\n",
    "plt.ylabel(\"probability to appear in first position\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy and torch seed for reproducibility\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "def generate_protein_string():\n",
    "    # generate from the model\n",
    "\n",
    "    # start_char_proba = {k: v / sum(counter.values()) for k, v in counter.items()}\n",
    "    start_char = np.random.choice(list(aa_to_proba_first.keys()), p=list(aa_to_proba_first.values()))\n",
    "    # context = torch.tensor([[stoi[start_char]]], dtype=torch.long, device=device)\n",
    "\n",
    "    initial_context = torch.tensor([[stoi[start_char]]], dtype=torch.long, device=DEVICE)  # (1, 1)\n",
    "\n",
    "    return decode(model.generate_line(idx=initial_context,\n",
    "                                      termination_token_idx=stoi[\"\\n\"],\n",
    "                                      pad_token_idx=stoi[\"!\"],\n",
    "                                      ).tolist()[:-1])  # remove the last \\n\n",
    "\n",
    "for _ in range(30):\n",
    "    print(generate_protein_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: with PyTorch Lightning\n",
    "### Defining the Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLNanoTransformer(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x, y, lengths):\n",
    "        return self.model(x, y, lengths)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, lengths = batch\n",
    "        _, loss = self.model(x, y, lengths)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.logger.experiment.add_scalar(\"train_loss\", loss, self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, lengths = batch\n",
    "        _, loss = self.model(x, y, lengths)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.logger.experiment.add_scalar(\"val_loss\", loss, self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "\n",
    "torch.manual_seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "inner_model = NanoTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embd=N_EMBD,\n",
    "    n_blocks=N_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    ")\n",
    "# inner_model = inner_model.to(DEVICE)\n",
    "\n",
    "nano_prot_gpt = PLNanoTransformer(inner_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Dataset and DataLoader\n",
    "\n",
    "We need to define a custome PyTorch `Dataset` which disambiguates between line indices and subsequence start indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDataset(Dataset):\n",
    "    def __init__(self, lines):\n",
    "        self.lines = sorted(lines, key=len, reverse=True)\n",
    "        nr_samples_per_line = [len(line) - BLOCK_SIZE for line in self.lines]\n",
    "        self.num_samples = sum(nr_samples_per_line)\n",
    "        self.line_idx_to_cumulative_nr_samples = np.array([0] + np.cumsum(nr_samples_per_line).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # infer line idx from idx, using binary search over line_idx_to_cumulative_nr_samples\n",
    "        # np.searchsorted() returns the index of the first element in the array that is greater than the value\n",
    "        line_idx = np.searchsorted(self.line_idx_to_cumulative_nr_samples, idx, side=\"right\") - 1\n",
    "        start_idx = idx - self.line_idx_to_cumulative_nr_samples[line_idx]\n",
    "\n",
    "        line = self.lines[line_idx]\n",
    "        line_encoded = encode_pad(line, BLOCK_SIZE)\n",
    "\n",
    "        x = torch.tensor(line_encoded[start_idx : start_idx + BLOCK_SIZE], dtype=torch.long)\n",
    "        y = torch.tensor(line_encoded[start_idx + 1 : start_idx + BLOCK_SIZE + 1], dtype=torch.long)\n",
    "        length = torch.tensor(min(len(line), BLOCK_SIZE), dtype=torch.long)\n",
    "        return x, y, length\n",
    "    \n",
    "# sampler = SubsequenceSampler(train_lines)\n",
    "train_dataset = LineDataset(train_lines)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True)\n",
    "\n",
    "val_dataset = LineDataset(val_lines)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1337\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/julien/miniconda3/envs/prot-gpt/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | NanoTransformer | 7.5 K \n",
      "------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ec3cd9baa343cab31a5a49676b7301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julien/miniconda3/envs/prot-gpt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/julien/miniconda3/envs/prot-gpt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176e60cc78d346bebf2713b648d5f831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c47fdcc19a24ee3ad9185ad73c93ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11391c599d5c40b9808cfcc3ac0427ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4dd8f2cf44497cad46500dac0f1b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(1337)\n",
    "\n",
    "logger = TensorBoardLogger(\"tensorboard_logs\", name=\"nano_prot_gpt\")\n",
    "\n",
    "# log hyperparameters\n",
    "logger.log_hyperparams({\n",
    "    \"block_size\": BLOCK_SIZE,\n",
    "    \"n_embd\": N_EMBD,\n",
    "    \"n_blocks\": N_BLOCKS,\n",
    "    \"num_heads\": NUM_HEADS,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"max_iters\": MAX_ITERS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "})\n",
    "\n",
    "trainer = pl.Trainer(max_steps=MAX_ITERS,\n",
    "                     val_check_interval=EVAL_INTERVAL,\n",
    "                     limit_val_batches=200,  # only run eval on 0.5% of the validation set\n",
    "                     callbacks=[TQDMProgressBar(refresh_rate=20)],\n",
    "                     precision=32,\n",
    "                     logger=logger,\n",
    "                     accelerator=DEVICE)\n",
    "\n",
    "trainer.fit(model=nano_prot_gpt, \n",
    "            train_dataloaders=train_loader, \n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Proper management of accelerators\n",
    "* Early stopping\n",
    "* `auto_lr_find`\n",
    "* Maybe `auto_scale_batch_size`\n",
    "* Maybe `gradient_clip_val`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce1b89515fef3d4cfef6e9104e9edf9e02f437173acd0f1472bac3c815597244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
